{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import scipy.spatial.distance\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.7327387580875756\n",
      "4 0.7770887149698589\n"
     ]
    }
   ],
   "source": [
    "with open('text.txt', 'r') as x:\n",
    "    text = x.read().lower() # считываем файл целиком и делаем нижний регистр\n",
    "    list_all = re.split('[^a-z]', text) # разбиваем в массив по пробелам и всяким знакам\n",
    "    \n",
    "    # проверяем все элементы грязного массива чтобы отбросить пустышки\n",
    "    list_clear2 = [] # пустой чистый массив\n",
    "    for i in list_all: \n",
    "        if i != '':\n",
    "            list_clear2 += [i]\n",
    "\n",
    "    # делаем массив из использованных слов по порядку (если слово уже было то не добавляем его)\n",
    "    slovar = []\n",
    "    for j in list_clear2:\n",
    "        if j not in slovar:\n",
    "            slovar += [j]\n",
    "    \n",
    "    # делаем словари: {порядковый_номер_слова:слово} и {слово:его_количество_в_тексте}\n",
    "    dict_slov = {}\n",
    "    obratny = {} \n",
    "    index = 0\n",
    "    for k in slovar:\n",
    "        dict_slov[index] = k\n",
    "        obratny [k] = index\n",
    "        index +=1\n",
    "    \n",
    "    # делаем массив из целых предложений\n",
    "    list_all = re.split('\\n', text) # массив в котором элементы это целые предложения\n",
    "    list_clear = [] # пустой чистый массив\n",
    "    for i in list_all: # берем одно предложение из массива\n",
    "        y = re.split('[^a-z]', i) # сплитим его чтобы оставить только слова. Но массив грязный (с пустышками)\n",
    "        element_clear = [] # пустой чистый массив\n",
    "        for k in y: # очищаем грязный массив от пустышек\n",
    "            if k != '':\n",
    "                element_clear += [k]\n",
    "        \n",
    "        \n",
    "        if element_clear != []: # в конце массива появлялся пустой элемент [''], это костыль чтобы его убрать\n",
    "            list_clear += [element_clear]\n",
    "            \n",
    "    \n",
    "    b = np.zeros((22,254)) # делаем нулевую матрицу\n",
    "    for z in range(0,len(list_clear)): # берем номер строки матрицы от 0 до 22\n",
    "        for m in list_clear[z]: #для каждого элемента строки считаем его и добавляем единичку в нулевой матрице 22на254  \n",
    "            b[z][obratny[m]] +=1 # тут используется словарь {слово:его_количество_в_тексте} чтобы по ключам находить значения\n",
    "    \n",
    "\n",
    "a = np.array((b)) # преобразуем в numpy матрицу\n",
    "cos_dist = {}\n",
    "# Считаем косинусное расстояние от предложения в самой первой строке (In comparison to dogs, cats have not undergone...) \n",
    "# до всех остальных с помощью функции scipy.spatial.distance.cosine. Складываем их в словарь\n",
    "for k in range (1,22):\n",
    "    cos_dist[scipy.spatial.distance.cosine(a[0,:],a[k,:])] = k\n",
    "\n",
    "menshie = sorted(cos_dist)[:2] # оставляем 2 наименьших значения\n",
    "to_out = [] # словарь для записи ответа в файл\n",
    "for i in menshie:\n",
    "    to_out += [cos_dist[i]]\n",
    "    print (cos_dist[i], i)\n",
    "    \n",
    "with open('Texts similarity_answer.txt', 'a') as result:\n",
    "    for k in to_out:\n",
    "        result.write(str(k)+' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', 'comparison', 'to', 'dogs', 'cats', 'have', 'not', 'undergone', 'major', 'changes', 'during', 'the', 'domestication', 'process']\n",
      "['domestic', 'cats', 'are', 'similar', 'in', 'size', 'to', 'the', 'other', 'members', 'of', 'the', 'genus', 'felis', 'typically', 'weighing', 'between', 'and', 'kg', 'and', 'lb']\n",
      "['in', 'one', 'people', 'deliberately', 'tamed', 'cats', 'in', 'a', 'process', 'of', 'artificial', 'selection', 'as', 'they', 'were', 'useful', 'predators', 'of', 'vermin']\n"
     ]
    }
   ],
   "source": [
    "print(list_clear[0])\n",
    "print(list_clear[6])\n",
    "print(list_clear[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized empty Git repository in C:/Users/igorl/Data researches/.git/\n"
     ]
    }
   ],
   "source": [
    "! git init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd mathematics_and_machine_learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master (root-commit) b16093f] first commit\n",
      " 3 files changed, 160 insertions(+)\n",
      " create mode 100644 README.md\n",
      " create mode 100644 mathematics_and_machine_learning/.ipynb_checkpoints/text_similarity-checkpoint.ipynb\n",
      " create mode 100644 mathematics_and_machine_learning/text_similarity.ipynb\n",
      "Branch 'main' set up to track remote branch 'main' from 'origin'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/igorlaryush/coursera_machine_learning_and_data_analyses.git\n",
      " * [new branch]      main -> main\n"
     ]
    }
   ],
   "source": [
    "! git commit -m \"first commit\"\n",
    "! git branch -M main\n",
    "! git remote add origin https://github.com/igorlaryush/coursera_machine_learning_and_data_analyses.git\n",
    "! git push -u origin main"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
